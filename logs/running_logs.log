  File "main.py", line 51, in <module>
    model_trainer.main()
  File "d:\text-summarization-nlp-project-main\src\textSummarizer\pipeline\stage_04_model_trainer.py", line 14, in main
    model_trainer_config.train()
  File "d:\text-summarization-nlp-project-main\src\textSummarizer\conponents\model_trainer.py", line 34, in train
    trainer_args = TrainingArguments(
  File "<string>", line 111, in __init__
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\transformers\training_args.py", line 1372, in __post_init__
    and (self.device.type != "cuda")
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\transformers\training_args.py", line 1795, in device
    return self._setup_devices
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\transformers\utils\generic.py", line 54, in __get__
    cached = self.fget(obj)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\transformers\training_args.py", line 1716, in _setup_devices
    raise ImportError(
ImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`
[2023-07-19 21:42:46,492: INFO: common: yaml file: config\config.yaml loaded successfully]
[2023-07-19 21:42:46,500: INFO: common: yaml file: params.yaml loaded successfully]
[2023-07-19 21:42:46,500: INFO: common: created directory at: artifacts]
[2023-07-19 21:42:46,500: INFO: common: created directory at: artifacts/model_evaluation]
[2023-07-19 21:42:46,502: ERROR: h11_impl: Exception in ASGI application
]
Traceback (most recent call last):
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\uvicorn\protocols\http\h11_impl.py", line 404, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\uvicorn\middleware\proxy_headers.py", line 78, in __call__
    return await self.app(scope, receive, send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\fastapi\applications.py", line 269, in __call__
    await super().__call__(scope, receive, send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\applications.py", line 124, in __call__
    await self.middleware_stack(scope, receive, send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\middleware\errors.py", line 184, in __call__
    raise exc
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\middleware\errors.py", line 162, in __call__
    await self.app(scope, receive, _send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\exceptions.py", line 93, in __call__
    raise exc
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\exceptions.py", line 82, in __call__
    await self.app(scope, receive, sender)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\fastapi\middleware\asyncexitstack.py", line 21, in __call__
    raise e
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\fastapi\middleware\asyncexitstack.py", line 18, in __call__
    await self.app(scope, receive, send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\routing.py", line 670, in __call__
    await route.handle(scope, receive, send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\routing.py", line 266, in handle
    await self.app(scope, receive, send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\routing.py", line 65, in app
    response = await func(request)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\fastapi\routing.py", line 227, in app
    raw_response = await run_endpoint_function(
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\fastapi\routing.py", line 160, in run_endpoint_function
    return await dependant.call(**values)
  File "app.py", line 41, in predict_route
    raise e
  File "app.py", line 38, in predict_route
    text = obj.predict(text)
  File "d:\text-summarization-nlp-project-main\src\textSummarizer\pipeline\prediction.py", line 13, in predict
    tokenizer = AutoTokenizer.from_pretrained(self.config.tokenizer_path)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\transformers\models\auto\tokenization_auto.py", line 652, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\transformers\models\auto\tokenization_auto.py", line 496, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\transformers\utils\hub.py", line 417, in cached_file
    resolved_file = hf_hub_download(
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\huggingface_hub\utils\_validators.py", line 110, in _inner_fn
    validate_repo_id(arg_value)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\huggingface_hub\utils\_validators.py", line 158, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'artifacts/model_trainer/tokenizer'. Use `repo_type` argument if needed.
[2023-07-19 21:42:56,056: INFO: common: yaml file: config\config.yaml loaded successfully]
[2023-07-19 21:42:56,057: INFO: common: yaml file: params.yaml loaded successfully]
[2023-07-19 21:42:56,058: INFO: common: created directory at: artifacts]
[2023-07-19 21:42:56,059: INFO: common: created directory at: artifacts/model_evaluation]
[2023-07-19 21:42:56,059: ERROR: h11_impl: Exception in ASGI application
]
Traceback (most recent call last):
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\uvicorn\protocols\http\h11_impl.py", line 404, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\uvicorn\middleware\proxy_headers.py", line 78, in __call__
    return await self.app(scope, receive, send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\fastapi\applications.py", line 269, in __call__
    await super().__call__(scope, receive, send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\applications.py", line 124, in __call__
    await self.middleware_stack(scope, receive, send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\middleware\errors.py", line 184, in __call__
    raise exc
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\middleware\errors.py", line 162, in __call__
    await self.app(scope, receive, _send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\exceptions.py", line 93, in __call__
    raise exc
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\exceptions.py", line 82, in __call__
    await self.app(scope, receive, sender)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\fastapi\middleware\asyncexitstack.py", line 21, in __call__
    raise e
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\fastapi\middleware\asyncexitstack.py", line 18, in __call__
    await self.app(scope, receive, send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\routing.py", line 670, in __call__
    await route.handle(scope, receive, send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\routing.py", line 266, in handle
    await self.app(scope, receive, send)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\starlette\routing.py", line 65, in app
    response = await func(request)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\fastapi\routing.py", line 227, in app
    raw_response = await run_endpoint_function(
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\fastapi\routing.py", line 160, in run_endpoint_function
    return await dependant.call(**values)
  File "app.py", line 41, in predict_route
    raise e
  File "app.py", line 38, in predict_route
    text = obj.predict(text)
  File "d:\text-summarization-nlp-project-main\src\textSummarizer\pipeline\prediction.py", line 13, in predict
    tokenizer = AutoTokenizer.from_pretrained(self.config.tokenizer_path)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\transformers\models\auto\tokenization_auto.py", line 652, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\transformers\models\auto\tokenization_auto.py", line 496, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\transformers\utils\hub.py", line 417, in cached_file
    resolved_file = hf_hub_download(
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\huggingface_hub\utils\_validators.py", line 110, in _inner_fn
    validate_repo_id(arg_value)
  File "D:\Text-Summarization-NLP-Project-main\text\lib\site-packages\huggingface_hub\utils\_validators.py", line 158, in validate_repo_id
    raise HFValidationError(
huggingface_hub.utils._validators.HFValidationError: Repo id must be in the form 'repo_name' or 'namespace/repo_name': 'artifacts/model_trainer/tokenizer'. Use `repo_type` argument if needed.
[2023-07-19 21:44:49,278: INFO: server: Shutting down]
[2023-07-19 21:44:49,382: INFO: on: Waiting for application shutdown.]
[2023-07-19 21:44:49,382: INFO: on: Application shutdown complete.]
[2023-07-19 21:44:49,382: INFO: server: Finished server process [16800]]
